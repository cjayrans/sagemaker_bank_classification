{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    Processor,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "\n",
    "from sagemaker import Model\n",
    "from sagemaker.xgboost import XGBoostPredictor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    CacheConfig,\n",
    "    TuningStep,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel, CreateModelStep\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "\n",
    "from sagemaker.workflow.functions import Join, JsonGet\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.tuner import (\n",
    "    ContinuousParameter,\n",
    "    IntegerParameter,\n",
    "    HyperparameterTuner,\n",
    "    WarmStartConfig,\n",
    "    WarmStartTypes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SageMaker Session\n",
    "\n",
    "region = sagemaker.Session().boto_region_name\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=boto_session, sagemaker_client=sm_client)\n",
    "work_directory = \"./\"\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "base_job_prefix = 'sagemaker/DEMO-xgboost-banking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker_session.upload_data(\n",
    "    path=\"{}/{}\".format(work_directory, \"bank-additional-full.csv\"),\n",
    "    bucket=default_bucket,\n",
    "    key_prefix=\"{}/{}\".format(base_job_prefix, \"data\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables and parameters needed for the Pipeline steps\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "model_package_group_name = \"banking-classification\"\n",
    "\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.t3.large\"\n",
    ")\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=os.path.join(\"s3://\",default_bucket, base_job_prefix, 'data/bank-additional-full.csv'),# f\"s3://sagemaker-servicecatalog-seedcode-{region}/dataset/abalone-dataset.csv\",\n",
    ")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "# Cache Pipeline steps to reduce execution time on subsequent executions\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "\"\"\"Feature engineers the banking dataset.\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection._base import SelectorMixin\n",
    "from sklearn.feature_extraction.text import _VectorizerMixin\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"age\",\n",
    "    \"job\", \n",
    "    \"marital\",\n",
    "    \"education\",\n",
    "    \"default\",\n",
    "    \"housing\",\n",
    "    \"loan\",\n",
    "    \"contact\",\n",
    "    \"month\",\n",
    "    \"day_of_week\",\n",
    "    \"duration\",\n",
    "    \"campaign\",\n",
    "    \"pdays\",\n",
    "    \"previous\",\n",
    "    \"poutcome\",\n",
    "    \"emp.var.rate\",\n",
    "    \"cons.price.idx\",\n",
    "    \"cons.conf.idx\",\n",
    "    \"euribor3m\",\n",
    "    \"nr.employed\",\n",
    "]\n",
    "label_column = \"y\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"age\": np.float64,\n",
    "    \"job\": str, \n",
    "    \"marital\": str,\n",
    "    \"education\": str,\n",
    "    \"default\": str,\n",
    "    \"housing\": str,\n",
    "    \"loan\": str,\n",
    "    \"contact\": str,\n",
    "    \"month\": str,\n",
    "    \"day_of_week\": str,\n",
    "    \"duration\": np.float64,\n",
    "    \"campaign\": np.float64,\n",
    "    \"pdays\": np.float64,\n",
    "    \"previous\": np.float64,\n",
    "    \"poutcome\": str,\n",
    "    \"emp.var.rate\": np.float64,\n",
    "    \"cons.price.idx\": np.float64,\n",
    "    \"cons.conf.idx\": np.float64,\n",
    "    \"euribor3m\": np.float64,\n",
    "    \"nr.employed\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"y\": str}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    \"\"\"Merges two dicts, returning a new copy.\"\"\"\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.debug(\"Starting preprocessing.\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input-data\", type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "    pathlib.Path(f\"{base_dir}/data\").mkdir(parents=True, exist_ok=True)\n",
    "    input_data = args.input_data\n",
    "    bucket = input_data.split(\"/\")[2]\n",
    "    key = \"/\".join(input_data.split(\"/\")[3:])\n",
    "    \n",
    "    logger.info(\"The key contains\", print(key))\n",
    "\n",
    "    logger.info(\"Downloading data from bucket: %s, key: %s\", bucket, key)\n",
    "    fn = f\"{base_dir}/data/banking-additional-full.csv\"\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    s3.Bucket(bucket).download_file(key, fn)\n",
    "\n",
    "    logger.debug(\"Reading downloaded data.\")\n",
    "    df = pd.read_csv(\n",
    "        fn,\n",
    "        header=0,\n",
    "#         names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    os.unlink(fn)\n",
    "    \n",
    "    logger.info(\"Downloaded df contains %s rows and %s columns\", df.shape[0], df.shape[1])\n",
    "    logger.debug(\"Defining transformers.\")\n",
    "    numeric_features = [\"age\", \"duration\", \"campaign\", \"pdays\",\"previous\",\"emp.var.rate\",\"cons.price.idx\",\"cons.conf.idx\",\"euribor3m\",\"nr.employed\"]\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"job\", \"marital\",\"education\",\"housing\",\"loan\",\"contact\",\"month\",\"day_of_week\",\"poutcome\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Applying transforms.\")\n",
    "    df['y'] = df['y'].map({'yes':1, 'no':0})\n",
    "    y = df.pop(\"y\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    \n",
    "    # estimate scale_pos_weight value\n",
    "#     counter = Counter(y)\n",
    "#     imbalance_ratio = counter[0] / counter[1]\n",
    "    \n",
    "    ### Create functions to retrieve the column names from the \"preprocess\" transformer\n",
    "    def get_feature_out(estimator, feature_in):\n",
    "        if hasattr(estimator,'get_feature_names'):\n",
    "            if isinstance(estimator, _VectorizerMixin):\n",
    "                # handling all vectorizers\n",
    "                return [f'vec_{f}' \\\n",
    "                    for f in estimator.get_feature_names()]\n",
    "            else:\n",
    "                return estimator.get_feature_names(feature_in)\n",
    "        elif isinstance(estimator, SelectorMixin):\n",
    "            return np.array(feature_in)[estimator.get_support()]\n",
    "        else:\n",
    "            return feature_in\n",
    "\n",
    "\n",
    "    def get_ct_feature_names(ct):\n",
    "        # handles all estimators, pipelines inside ColumnTransfomer\n",
    "        # doesn't work when remainder =='passthrough'\n",
    "        # which requires the input column names.\n",
    "        output_features = []\n",
    "\n",
    "        for name, estimator, features in ct.transformers_:\n",
    "            if name!='remainder':\n",
    "                if isinstance(estimator, Pipeline):\n",
    "                    current_features = features\n",
    "                    for step in estimator:\n",
    "                        current_features = get_feature_out(step, current_features)\n",
    "                    features_out = current_features\n",
    "                else:\n",
    "                    features_out = get_feature_out(estimator, features)\n",
    "                output_features.extend(features_out)\n",
    "            elif estimator=='passthrough':\n",
    "                output_features.extend(ct._feature_names_in[features])\n",
    "\n",
    "        return output_features\n",
    "\n",
    "    X = pd.DataFrame(X_pre, \n",
    "                 columns=get_ct_feature_names(preprocess))\n",
    "\n",
    "    X['y'] = y\n",
    "    \n",
    "    # Move our target column from the first to the last position (column) in the data frame\n",
    "    temp_cols = list(X.columns)\n",
    "    temp_cols = [temp_cols[-1]] + temp_cols[:-1]\n",
    "    X = X[temp_cols]\n",
    "\n",
    "    logger.info(\"Splitting %d rows of data into train, validation, test datasets.\", len(X))\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    logger.info(\"Writing out datasets to %s.\", base_dir)\n",
    "    train.to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    validation.to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    test.to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=f\"{base_job_prefix}/sklearn-banking-preprocess\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "data_repo_prefix=\"{}/{}\".format(base_job_prefix, \"data\")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessBankingDataForHPO\",\n",
    "    processor=sklearn_processor,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "            destination=f\"s3://{default_bucket}/{data_repo_prefix}/{ExecutionVariables.PIPELINE_EXECUTION_ID}/PreprocessBankingDataForHPO)\",\n",
    "#             destination=Join(\n",
    "#                 on=\"/\",\n",
    "#                 values=[\n",
    "#                     \"s3:/\",\n",
    "#                     default_bucket,\n",
    "# #                     base_job_prefix,\n",
    "#                       data_repo_prefix,\n",
    "#                     ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "#                     \"PreprocessBankingDataForHPO\",\n",
    "#                 ],\n",
    "#             ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "            destination=f\"s3://{default_bucket}/{data_repo_prefix}/{ExecutionVariables.PIPELINE_EXECUTION_ID}/PreprocessBankingDataForHPO)\",\n",
    "#             destination=Join(\n",
    "#                 on=\"/\",\n",
    "#                 values=[\n",
    "#                     \"s3:/\",\n",
    "#                     default_bucket,\n",
    "# #                     base_job_prefix,\n",
    "#                     data_repo_prefix,\n",
    "#                     ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "#                     \"PreprocessBankingDataForHPO\",\n",
    "#                 ],\n",
    "#             ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=f\"s3://{default_bucket}/{data_repo_prefix}/{ExecutionVariables.PIPELINE_EXECUTION_ID}/PreprocessBankingDataForHPO)\",\n",
    "#             destination=Join(\n",
    "#                 on=\"/\",\n",
    "#                 values=[\n",
    "#                     \"s3:/\",\n",
    "#                     default_bucket,\n",
    "# #                     base_job_prefix,\n",
    "#                     data_repo_prefix,\n",
    "#                     ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "#                     \"PreprocessBankingDataForHPO\",\n",
    "#                 ],\n",
    "#             ),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"preprocess.py\",\n",
    "    job_arguments=[\"--input-data\", input_data],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path for the model artifacts from the Hyperparameter Tuning Job\n",
    "model_path = f\"s3://{default_bucket}/{base_job_prefix}/BankingTrain\"\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"{base_job_prefix}/banking-train\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "xgb_train.set_hyperparameters(\n",
    "    eval_metric=\"logloss\",\n",
    "    objective=\"binary:logistic\",  # Define the object metric for the training job\n",
    "    num_round=30,\n",
    "    eta=0.1,\n",
    "    gamma=4,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.7,\n",
    "    silent=0,\n",
    "    scale_pos_weight=7.7, # Based on imbalance_ratio calculation listed in the preprocess.py script\n",
    ")\n",
    "\n",
    "objective_metric_name = \"validation:logloss\"\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0.01, 10.0),  # , scaling_type=\"Logarithmic\"\n",
    "    \"lambda\": ContinuousParameter(0.01, 10.0),  # , scaling_type=\"Logarithmic\"\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "\n",
    "tuner_log = HyperparameterTuner(\n",
    "    xgb_train,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    strategy=\"Bayesian\",\n",
    "    objective_type=\"Minimize\",\n",
    "    early_stopping_type = 'Auto'\n",
    ")\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name=\"HPTuning\",\n",
    "    tuner=tuner_log,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 2 SageMaker Models\n",
    "\n",
    "model_bucket_key = f\"{default_bucket}/{base_job_prefix}/BankingTrain\"\n",
    "best_model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_bucket_key),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    predictor_cls=XGBoostPredictor,\n",
    ")\n",
    "\n",
    "step_create_first = CreateModelStep(\n",
    "    name=\"CreateTopModel\",\n",
    "    model=best_model,\n",
    "    inputs=sagemaker.inputs.CreateModelInput(instance_type=\"ml.m4.large\"),\n",
    ")\n",
    "\n",
    "# second_best_model = Model(\n",
    "#     image_uri=image_uri,\n",
    "#     model_data=step_tuning.get_top_model_s3_uri(top_k=1, s3_bucket=model_bucket_key),\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "#     role=role,\n",
    "#     predictor_cls=XGBoostPredictor,\n",
    "# )\n",
    "\n",
    "# step_create_second = CreateModelStep(\n",
    "#     name=\"CreateSecondBestModel\",\n",
    "#     model=second_best_model,\n",
    "#     inputs=sagemaker.inputs.CreateModelInput(instance_type=\"ml.m4.large\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile evaluate.py\n",
    "\n",
    "\"\"\"Evaluation script for measuring mean squared error.\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import auc, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.debug(\"Starting evaluation.\")\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    logger.debug(\"Loading xgboost model.\")\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    logger.debug(\"Reading test data.\")\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    logger.debug(\"Reading test data.\")\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "    ######\n",
    "\n",
    "    logger.info(\"Performing predictions against test data.\")\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.round(predictions)\n",
    "    logger.info(\"Predictions are of data type %s \", predictions.dtype)\n",
    "    logger.info(\"Y Test are of data type %s \", y_test.dtype)\n",
    "\n",
    "    logger.debug(\"Calculating mean squared error.\")\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"auc\": {\"value\": auc},\n",
    "            \"precision\": {\"value\": precision},\n",
    "            \"recall\": {\"value\": recall},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.info(\"Writing out evaluation report with precision: %f and Recall: %f and an AUC of %f \" , precision, recall, auc)\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ProcessingStep is used to evaluate the performance of a selected model from the HPO step. In this case, the top performing model\n",
    "# is evaluated. Based on the results of the evaluation, the model is registered into the Model Registry using a ConditionStep.\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{base_job_prefix}/script-tuning-step-eval\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"BestTuningModelEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "# This can be extended to evaluate multiple models from the HPO step\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateTopModel\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_bucket_key),\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model in the Model Registry\n",
    "# Multiple models can be registered into the Model Registry using multiple RegisterModel steps. These models can either be added to the\n",
    "# same model package group as different versions within the group or the models can be added to different model package groups.\n",
    "\n",
    "step_register_best = RegisterModel(\n",
    "    name=\"RegisterBestBankingModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_bucket_key),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"application/json\"], # \"text/csv\"\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition step for evaluating model quality and branching execution\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"classification_metrics.auc.value\",\n",
    "    ),\n",
    "    right=0.8,\n",
    ")\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCBankingEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register_best],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"tuning-step-pipeline\",\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        input_data,\n",
    "        model_approval_status,\n",
    "    ],\n",
    "    steps=[\n",
    "        step_process,\n",
    "        step_tuning,\n",
    "        step_create_first,\n",
    "#         step_create_second,\n",
    "        step_eval,\n",
    "        step_cond,\n",
    "    ],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Endpoint with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "bucket='stackvidhya'\n",
    "\n",
    "file_key = 'sagemaker/DEMO-xgboost-banking/data/bilcu1istvih/PreprocessBankingDataForHPO/test.csv'\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "obj = s3_client.get_object(Bucket=default_bucket, Key=file_key)\n",
    "\n",
    "test_df = pd.read_csv(io.BytesIO(obj['Body'].read()), header=None)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df.iloc[:, 0]\n",
    "# y_test = y_test.astype(int)\n",
    "test_x = test_df.iloc[:, 1:]\n",
    "\n",
    "# subset_test_df = test_df.iloc[0:5, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "# sm_client = boto3.client(\"sagemaker\")\n",
    "endpoint_name = \"bankingClassificationEndpoint\"\n",
    "\n",
    "# csv serialization\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=test_x.to_csv(header=False, index=False).encode(\"utf-8\"),\n",
    "    ContentType=\"text/csv\",\n",
    ")\n",
    "\n",
    "predictions = response[\"Body\"].read()\n",
    "# print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.decode('utf-8')\n",
    "predictions = predictions.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions += [float(r) for r in predictions]\n",
    "predictions = [float(r) for r in predictions]\n",
    "# float(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predict_probability'] = predictions\n",
    "test_df['predict_binary'] = np.round(predictions).astype(int)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "auc = roc_auc_score(y_test, test_df['predict_binary'])\n",
    "precision = precision_score(y_test, test_df['predict_binary'])\n",
    "recall = recall_score(y_test, test_df['predict_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Testing model performance returned an AUC of {auc} along with a Precision score of {precision} and a Recall score of {recall} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
